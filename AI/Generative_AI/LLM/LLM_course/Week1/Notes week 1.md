Some interesting key concepts we will be touching:

How to choose a model:
- Open-Source
- Closed Source
- Multi-modal (Image and audio gen)
- Architecture ([[Encoders-Decoders]])
- Selecting

What tools we have for choosing a model:
- Huggingface
- LangChain
- Gradio
- Weights & Biases 
- Modal (deployment to production)

What techniques there are for applications:
- APIs
- Multi-shot prompting
- RAG (Retrieval Augmented generation)
- Fine-tuning
- Agentization

### Paradigms for running LLMs:

- Chat interfaces (Like OpenAI chat gpt)
- Cloud APIs like in day 1, you interface with a model running on the cloud through an API
- Direct inference: 
	Huggingface's Transformers library.
	Ollama's local host.

[[day2 note]] 

