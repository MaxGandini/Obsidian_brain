`olamma3.3` eats up a whopping 45 Gb of RAM. So as an excercise I'm going to host the lighter `gemma` . A good practice target is going to be applying the summarization implementing yesterday's code with ollama, but this time to the [[Attention is all you need]] paper.

