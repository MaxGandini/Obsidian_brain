In mathematics a time series is a series of data points indexed in time order. It is a time series with a sequence taken at successive equally spaced points in time. Thus it is a sequence of discrete time data.

Some conventional examples used in machine learning for time series:

- [[ARIMA-X]]
- [[ARMA]]
- [[RNN]] (Recurrent neural-networks) like LSTM.

The typical understanding of "time series" applications in [[Machine Learning]] is that this series of data points indexed in time order, has a [[Correlation]] . The extent of that correlation can be limited to the previous step, or it can reach up to many steps, introducing a typical variable called *lag*.