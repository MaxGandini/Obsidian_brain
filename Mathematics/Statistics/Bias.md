Bias measures the error introduced by approximating a complex real-world problem with a simpler model. It reflects the assumptions made by the model to capture the relationship between features and the target variable.

High bias leads to underfitting, where the model is too simple to capture the patterns in the data accurately.

Mathematically, bias is defined as the difference between the expected prediction of the model and the true values:

$$ \text{Bias}^2 = \left( \mathbb{E}[\hat{y}] - y \right)^2 $$
